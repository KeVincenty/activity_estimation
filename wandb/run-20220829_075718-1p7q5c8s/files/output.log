--------------------------------------------------------------------------------
initializing train set!
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
initializing val set!
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
initializing test set!
--------------------------------------------------------------------------------
dropout used:[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
--------------------------------------------------------------------------------
model size
TextTransformer: 244.96MB
AttModule: 274.05MB
FusionTransformer: 1953.12MB
total size: 2472.12MB
--------------------------------------------------------------------------------
Using AdamW as optimizer
learning rate is 0.0005 for TextTransformer
learning rate is 0.0005 for AttModule
learning rate is 0.0005 for FusionTransformer
Traceback (most recent call last):
  File "main.py", line 291, in <module>
    main()
  File "main.py", line 166, in main
    lr_scheduler = build_lr_scheduler(config, optimizer)
  File "/root/workspace/activity_estimation/utils/solver.py", line 58, in build_lr_scheduler
    decay_steps = config["train"]["steps_per_epoch"] * (config["train"]["lr_scheduler"]["epochs"] - config["train"]["lr_scheduler"]["lr_decay_epoch"])
KeyError: 'epochs'